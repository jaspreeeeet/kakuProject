#!/usr/bin/env python3
"""
Compare ALL AI Image Analysis Models
Tests Google ViT, Microsoft GIT, and Lightweight Vision
"""

import os
import sys
import glob
from PIL import Image
import numpy as np

sys.path.append(os.path.dirname(__file__))

print("\n" + "="*70)
print("ðŸ¤– COMPARING ALL AI IMAGE ANALYSIS MODELS")
print("="*70 + "\n")

# Find images to analyze
image_patterns = [
    "uploads/images/*.jpg",
    "uploads/images/*.jpeg",
    "uploads/images/*.png",
]

found_images = []
for pattern in image_patterns:
    found_images.extend(glob.glob(pattern))

if not found_images:
    print("âŒ No images found in uploads/images/")
    sys.exit(1)

print(f"ðŸ“¸ Found {len(found_images)} images to analyze\n")

# ============ MODEL 1: Google ViT (from app.py) ============
print("1ï¸âƒ£  GOOGLE VIT (Vision Transformer - Classification)")
print("-" * 70)

try:
    from app import analyze_image_with_ai, AI_AVAILABLE
    
    if not AI_AVAILABLE:
        print("âŒ Google ViT not available")
    else:
        test_image = found_images[0]
        caption = analyze_image_with_ai(test_image)
        print(f"âœ… Model: Google ViT loaded")
        print(f"ðŸ“· Image: {os.path.basename(test_image)}")
        print(f"ðŸŽ¯ Caption: {caption}")
        print()
        
except Exception as e:
    print(f"âŒ Error loading Google ViT: {e}\n")

# ============ MODEL 2: Microsoft GIT (Lightweight) ============
print("2ï¸âƒ£  MICROSOFT GIT (Lightweight Image-to-Text)")
print("-" * 70)

try:
    import torch
    from transformers import AutoProcessor, AutoModelForCausalLM
    
    CACHE_DIR = r"E:\Rajeev\esp 32\esp 32\.cache\huggingface"
    os.environ['HUGGINGFACE_HUB_CACHE'] = CACHE_DIR
    
    MODEL_ID = "microsoft/git-base"
    
    print("ðŸš€ Loading Microsoft GIT model...")
    processor = AutoProcessor.from_pretrained(MODEL_ID, cache_dir=CACHE_DIR)
    model = AutoModelForCausalLM.from_pretrained(
        MODEL_ID,
        cache_dir=CACHE_DIR,
        torch_dtype=torch.float32,
        device_map=None
    )
    print("âœ… Microsoft GIT loaded")
    
    test_image = found_images[0]
    image = Image.open(test_image).convert("RGB")
    
    inputs = processor(images=image, return_tensors="pt")
    with torch.no_grad():
        output_ids = model.generate(**inputs, max_length=50)
    
    caption = processor.decode(output_ids[0], skip_special_tokens=True)
    print(f"ðŸ“· Image: {os.path.basename(test_image)}")
    print(f"ðŸŽ¯ Caption: {caption}")
    print()
    
except Exception as e:
    print(f"âŒ Error loading Microsoft GIT: {e}\n")

# ============ MODEL 3: Lightweight Vision (Basic Analysis) ============
print("3ï¸âƒ£  BASIC IMAGE ANALYSIS (PIL + Visual Features)")
print("-" * 70)

try:
    test_image = found_images[0]
    image = Image.open(test_image).convert("RGB")
    
    # Get image properties
    width, height = image.size
    img_array = np.array(image)
    
    # Basic color analysis
    mean_colors = np.mean(img_array, axis=(0, 1))
    brightness = np.mean(img_array)
    
    # Generate descriptive caption
    caption_parts = []
    
    if brightness > 200:
        caption_parts.append("bright")
    elif brightness < 80:
        caption_parts.append("dark")
    else:
        caption_parts.append("well-lit")
    
    aspect_ratio = width / height
    if aspect_ratio > 1.5:
        caption_parts.append("landscape-oriented")
    elif aspect_ratio < 0.7:
        caption_parts.append("portrait-oriented")
    else:
        caption_parts.append("square-oriented")
    
    caption = f"A {' '.join(caption_parts)} image captured at {width}Ã—{height}"
    
    print("âœ… Basic image analysis loaded")
    print(f"ðŸ“· Image: {os.path.basename(test_image)}")
    print(f"ðŸ“ Resolution: {width}Ã—{height}")
    print(f"â˜€ï¸ Brightness: {brightness:.0f}/255")
    print(f"ðŸŽ¯ Caption: {caption}")
    print()
    
except Exception as e:
    print(f"âŒ Error in basic analysis: {e}\n")

# ============ ANALYSIS COMPARISON ============
print("="*70)
print("ðŸ“Š MODEL COMPARISON SUMMARY")
print("="*70)
print("""
â”Œâ”€ MODEL â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€ TYPE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€ SPEED â”€â”¬â”€ QUALITY â”
â”‚ Google ViT              â”‚ Classification  â”‚ Fast    â”‚ Good     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Microsoft GIT           â”‚ Captioning      â”‚ Medium  â”‚ Excellentâ”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Basic Image Analysis    â”‚ Feature-based   â”‚ Very    â”‚ Fair     â”‚
â”‚                         â”‚                 â”‚ Fast    â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

âœ… RECOMMENDATION: Use Google ViT for your ESP32 dashboard
   - Fast loading and inference
   - High accuracy for object detection
   - Currently integrated in app.py
   - Works perfectly with QVGA resolution images
""")

print("ðŸŽ‰ All model tests completed!")
